{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Model of Spatial Auditory Attention\n",
    "\n",
    "### Table of Contents\n",
    "* [Basic model setup](cmsaa.ipynb#Basic-Model-Setup)\n",
    "* * [Goal Map](cmsaa.ipynb#Goal-Maps)\n",
    "* * [Saliency Map](cmsaa.ipynb#Saliency-Maps)\n",
    "* * [Priority Map](cmsaa.ipynb#Priority-Maps)\n",
    "* * [Attentional Bias](cmsaa.ipynb#Attentional-Bias)\n",
    "* [Fitting model to the data](cmsaa.ipynb#Fitting-the-Priority-Map-to-the-Data)\n",
    "* [180 Degree Model](cmsaa-180.ipynb#180-Degre-Data)\n",
    "* * [180 Degree Data](cmsaa-180.ipynb#180-Degree-Data)\n",
    "* * [180 Degree Results](cmsaa-180.ipynb#180-Degree-Results)\n",
    "* [360 Degree Model](cmsaa-180.ipynb#180-Degre-Data)\n",
    "* * [360 Degree Data](cmsaa-180.ipynb#180-Degree-Data)\n",
    "* * [360 Degree Results](cmsaa-180.ipynb#180-Degree-Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model Setup\n",
    "\n",
    "### Goal Maps\n",
    "\n",
    "#### Standard\n",
    "\n",
    "Top-down attentional bias is represented as a gaussian curve, with the highest amount of attentional bias focused at the attended location. Less attentional bias is applied to locations further from the attended location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalMap:\n",
    "    def __init__(self, attended_location):\n",
    "        self.attended_location = attended_location\n",
    "    \n",
    "    def standard(self, x, mag, stdev):\n",
    "        # gaussian equation\n",
    "        return mag * np.exp(-abs(self.attended_location-x)**2 / (2*stdev**2))\n",
    "    \n",
    "    # shifts the goal map up or down by the minshift value\n",
    "    def standard_minshift(self, x, mag, stdev, minshift):\n",
    "        return minshift + standard(x,stdev, mag)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency Maps \n",
    "\n",
    "Bottom up attentional bias can be represented as an inverted gaussian curve or as a constant value across all locations.\n",
    "\n",
    "#### Experimental\n",
    "\n",
    "The saliency may be learned from the data using Instance Based Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaliencyMap:\n",
    "    def __init__(self, attended_location):\n",
    "        self.attended_location = attended_location\n",
    "    \n",
    "    def standard(self, x, mag, stdev):\n",
    "        # inverted gaussian equation\n",
    "        return mag - mag * np.exp(-abs(self.attended_location-x)**2 / (2*stdev**2))\n",
    "    \n",
    "    # returns a constant attentional bias at every location in the map range\n",
    "    def constant(self, x, value):\n",
    "        return [value]*len(x)\n",
    "    \n",
    "    # returns a map where each degree location in the map range represents the probability of a sound at that location.\n",
    "    # Probabilities are learned from the individual trials\n",
    "    # Inputs: x - a list representing the range of locations that sounds can be presented from\n",
    "    #         attended_location - represents the attended location for the current condition (probably -90,0,90 in the 180 degree case)\n",
    "    #         trials - a 2d list, where each row contains [trial id, sound location and frequency] \n",
    "    # Outputs: saliency map - a list of size x. Each item in the list contains the probability that a sound will come from that location.\n",
    "    #                         Probability is calculated using the equations found in Lejarraga 2010. https://onlinelibrary.wiley.com/doi/abs/10.1002/bdm.722 \n",
    "    def ibl(self, x, attended_location, trials):\n",
    "        \n",
    "        saliency_map = []\n",
    "        \n",
    "        # TODO: replace this with IBL algorithm\n",
    "        # - Calculate the activation for each trial in trials (Equation 3 in paper)\n",
    "        # - For each location in x:\n",
    "        # - - calculate the activation value as if that location were the next trial in trials (trial id + 1) (Equation 3 in paper)\n",
    "        # - - calculate the probability of a sound coming from that location (Equation 2 in paper)\n",
    "        # - - append probability to saliency_map.\n",
    "        \n",
    "        # given a 2d array of data (each row represents one trial)\n",
    "        return saliency_map\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priority Maps\n",
    "\n",
    "The priority map represents the total attentional bias at a given location. It is calculated by adding the bias from the goal map to the bias supplied by the saliency map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityMap:\n",
    "    def __init__(self, attended_location):\n",
    "        self.attended_location = attended_location\n",
    "        \n",
    "    def standard(self, x, gm_mag, gm_stdev, sm_mag, sm_stdev):\n",
    "        \n",
    "        gm = GoalMap(self.attended_location)\n",
    "        sm = SaliencyMap(self.attended_location)\n",
    "        \n",
    "        self.goalmap = gm.standard(x, gm_mag, gm_stdev)\n",
    "        self.saliencymap = sm.standard(x, sm_mag, sm_stdev)\n",
    "        self.prioritymap = self.goalmap + self.saliencymap\n",
    "        \n",
    "        return self.prioritymap\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attentional Bias\n",
    "\n",
    "Attentional bias represents how much attention is available at each spatial location. It has an inverse relationship to reaction times, such that more attention leads to faster reaction times, and less attentional bias leads to slower reaction times. \n",
    "\n",
    "The mean reaction times from the data are converted to an attentional bias value using the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attentional_bias(expRTs):\n",
    "    \n",
    "    return (2000 - np.array(expRTs))/2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Priority Map to the Data\n",
    "\n",
    "The priority map is fit to the data using the curve_fit function available in the scipy library. \n",
    "curve_fit expects the function to be fit (the priority map), the range of values to fit, the data to fit the funtion to, initial parameter values and the bounds, or constraints on what the parameter values are allowed to be.\n",
    "\n",
    "curve_fit returns a list of the optimal parameter values found and the estimated covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_prioritymap(attended_location, x, y, init_vals, min_bounds, max_bounds):\n",
    "\n",
    "    pm = PriorityMap(attended_location)\n",
    "\n",
    "    (best_vals,covar) = curve_fit(pm.standard, x, y, p0=init_vals, bounds=(min_bounds,max_bounds))\n",
    "\n",
    "    return best_vals                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Error\n",
    "\n",
    "The root mean squared error between the optimized curve and the data can be found using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(xs,pm,experimental):\n",
    "    error = 0\n",
    "    \n",
    "    i = 0\n",
    "    for x in xs:\n",
    "        error += (experimental[i] - pm[x]) ** 2\n",
    "        i += 1\n",
    "        \n",
    "    return error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
